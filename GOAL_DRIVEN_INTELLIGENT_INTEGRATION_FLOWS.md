# üéØ Goal-Driven Intelligent Integration System - Core Flows

**Version**: Production Ready v1.0  
**Status**: ‚úÖ OPERATIONAL (Score: 92/100)  
**Last Updated**: 2025-09-06  

---

## üèóÔ∏è **ARCHITECTURAL PRESERVATION GUIDE**

> **‚ö†Ô∏è CRITICAL**: Questo documento definisce i flussi core del sistema orchestrato intelligente. 
> **Ogni modifica al sistema DEVE preservare questi flussi** per mantenere l'intelligenza collettiva.

---

## üß† **1. MEMORY-ENHANCED TASK GENERATION FLOW**

### **Input**: Goal bloccato al 0% 
### **Output**: Task intelligenti basati su memoria storica

```python
# FLUSSO CORE - NON MODIFICARE
async def memory_enhanced_task_generation(workspace_id: str, goal_id: str):
    """üß† CORE FLOW: Task generation con memoria workspace"""
    
    # 1. Recupera insights storici dalla memoria
    workspace_memory_insights = await workspace_memory_system.get_relevant_insights(
        workspace_id=workspace_id,
        context_type="task_execution",
        limit=50
    )
    
    # 2. Categorizza insights per task generation
    context = {
        "success_patterns": workspace_memory_insights.get("success_patterns", []),
        "failure_lessons": workspace_memory_insights.get("failure_lessons", []),
        "best_practices": workspace_memory_insights.get("best_practices", [])
    }
    
    # 3. Genera task con AI enhancement
    enhanced_prompt = f"""
    Genera task per {goal_description} usando:
    
    SUCCESS PATTERNS da replicare:
    {[pattern.get('pattern', '') for pattern in context['success_patterns'][:3]]}
    
    FAILURE LESSONS da evitare: 
    {[lesson.get('pattern', '') for lesson in context['failure_lessons'][:3]]}
    
    BEST PRACTICES da applicare:
    {[practice.get('recommendation', '') for practice in context['best_practices'][:3]]}
    """
    
    # 4. Crea task con context storico
    return await ai_task_planner.generate_tasks(enhanced_prompt)
```

---

## üîç **2. INTELLIGENT RAG TRIGGER FLOW**

### **Input**: Task da eseguire
### **Output**: Task potenziato con documento context (se necessario)

```python
# FLUSSO CORE - NON MODIFICARE  
async def intelligent_rag_enhancement(task_data: Dict, workspace_id: str):
    """üîç CORE FLOW: Automatic RAG triggering per task execution"""
    
    # 1. AI-driven analysis per determinare necessit√† RAG
    should_search, queries, confidence = await intelligent_rag_trigger.should_trigger_document_search(
        task_name=task_data.get("name", ""),
        task_description=task_data.get("description", ""),
        task_type=task_data.get("type"),
        execution_context=task_data.get("context")
    )
    
    # 2. Se confidence > 0.7, esegui ricerca documenti
    if should_search and confidence > 0.7:
        logger.info(f"üîç RAG triggered with {confidence:.2f} confidence")
        
        search_results = await intelligent_rag_trigger.execute_intelligent_document_search(
            workspace_id=workspace_id,
            agent_id=task_data["agent_id"],
            search_queries=queries,
            max_results_per_query=3
        )
        
        # 3. Potenzia task con documento context
        task_data["enhanced_context"] = {
            "documents_found": search_results["documents_found"],
            "relevant_content": search_results["results"],
            "search_queries_used": search_results["queries_used"]
        }
    
    return task_data
```

---

## üö¶ **3. PRE-EXECUTION QUALITY GATES FLOW**

### **Input**: Task pronto per esecuzione
### **Output**: Approvazione/blocco con enhancement context

```python
# FLUSSO CORE - NON MODIFICARE
async def pre_execution_quality_validation(task: Task, agent: AgentModel, workspace_context: Dict):
    """üö¶ CORE FLOW: 6 quality gates validation"""
    
    # Esegue tutti i 6 quality gates in sequenza
    can_proceed, gate_results, enhanced_context = await pre_execution_quality_gates.run_all_gates(
        task=task,
        agent=agent, 
        workspace_context=workspace_context
    )
    
    # GATES OBBLIGATORI:
    # 1. Task Completeness - Campi richiesti e ben formati
    # 2. Agent Readiness - Agent attivo e competente 
    # 3. Resource Availability - Tools e documenti disponibili
    # 4. Dependency Resolution - Prerequisiti completati
    # 5. Anti-Pattern Detection - AI rileva problemi noti
    # 6. Memory Insights - Controlla failure patterns storici
    
    if not can_proceed:
        failed_gates = [r for r in gate_results if r.status == "failed"]
        logger.error(f"‚ùå Task blocked by quality gates: {[g.gate_name for g in failed_gates]}")
        return False, gate_results
    
    logger.info(f"‚úÖ All quality gates passed - task ready for execution")
    return True, enhanced_context
```

---

## üîÑ **4. SYSTEMATIC LEARNING CAPTURE FLOW**

### **Input**: Task execution completato
### **Output**: Patterns salvati in memoria per future task

```python
# FLUSSO CORE - NON MODIFICARE
async def systematic_learning_capture(task: Task, execution_result: TaskExecutionOutput):
    """üîÑ CORE FLOW: Learning capture da ogni task execution"""
    
    # 1. AI analysis dell'outcome
    if systematic_learning_loops.ai_available:
        learnings = await systematic_learning_loops._ai_analyze_outcome(
            outcome_data={
                "task_name": task.name,
                "execution_status": execution_result.status,
                "execution_summary": execution_result.summary,
                "error_message": execution_result.error_message
            },
            task=task,
            execution_result=execution_result
        )
    else:
        # Fallback rule-based
        learnings = await systematic_learning_loops._rule_based_analysis(
            outcome_data, execution_result
        )
    
    # 2. Categorizza learnings per workspace memory
    if learnings and learnings.get("memory_metadata", {}).get("should_remember", False):
        memory_entry = {
            "workspace_id": task.workspace_id,
            "memory_type": "task_execution_learning",
            "content": {
                "success_patterns": learnings.get("success_patterns", []),
                "failure_lessons": learnings.get("failure_lessons", []), 
                "best_practices": learnings.get("best_practices", []),
                "optimization_opportunities": learnings.get("optimization_opportunities", [])
            }
        }
        
        # 3. Salva in workspace memory per future task
        await workspace_memory_system.store_memory(memory_entry)
        
        logger.info(f"üìù Learning captured and stored for future task generation")
```

---

## üéØ **5. HOLISTIC INTEGRATION PIPELINE FLOW**

### **Input**: Task assignment da Manager
### **Output**: Task completato con learning integrato

```python
# FLUSSO CORE COMPLETO - NON MODIFICARE
async def holistic_intelligent_pipeline(task_data: Dict, agent_id: str, workspace_id: str):
    """üéØ CORE FLOW: Pipeline completo end-to-end"""
    
    # FASE 1: Memory Enhancement
    workspace_context = await goal_driven_task_planner._get_workspace_memory_insights(workspace_id)
    
    # FASE 2: RAG Intelligence (se necessario)
    enhanced_task_data = await intelligent_rag_enhancement(task_data, workspace_id)
    
    # FASE 3: Quality Gates Validation  
    task = Task.model_validate(enhanced_task_data)
    agent = await get_agent_by_id(agent_id)
    
    can_proceed, enhanced_context = await pre_execution_quality_validation(
        task, agent, workspace_context
    )
    
    if not can_proceed:
        return {"success": False, "blocked_by_quality_gates": True}
    
    # FASE 4: Task Execution (con enhanced context)
    execution_result = await execute_task_with_enhanced_context(
        task_data=enhanced_task_data,
        enhanced_context=enhanced_context,
        agent_id=agent_id
    )
    
    # FASE 5: Learning Capture
    await systematic_learning_capture(task, execution_result)
    
    # FASE 6: Update Goal Progress
    await update_goal_progress_with_task_completion(task.goal_id, execution_result)
    
    return execution_result
```

---

## ü§ù **6. MANAGER-AGENT HANDOFF FLOW**

### **Input**: Complex goal requiring multiple agents
### **Output**: Coordinated execution con handoff intelligenti

```python
# FLUSSO CORE - NON MODIFICARE
async def manager_coordinated_handoff(goal_context: Dict, workspace_id: str):
    """ü§ù CORE FLOW: Manager coordination con intelligent handoff"""
    
    # 1. Manager analizza e crea execution plan
    execution_plan = await manager_agent.create_execution_plan(goal_context)
    
    results = []
    for step in execution_plan["steps"]:
        
        # 2. Selezione agente basata su competenze + memoria storica
        selected_agent = await manager_agent.select_best_agent(
            step["description"], 
            workspace_context=await get_workspace_context_with_memory(workspace_id),
            agent_performance_history=await get_agent_performance_patterns(workspace_id)
        )
        
        # 3. Handoff coordinato con context completo
        handoff_prompt = f"""
        ü§ù COORDINATED HANDOFF
        
        Agent: {selected_agent}
        Step: {step["sequence_number"]}/{len(execution_plan["steps"])}
        Task: {step["description"]}
        
        CONTEXT FROM PREVIOUS STEPS:
        {format_previous_results(results)}
        
        MEMORY PATTERNS TO FOLLOW:
        Success Patterns: {step.get("applicable_success_patterns", [])}
        Failure Lessons: {step.get("applicable_failure_lessons", [])}
        
        QUALITY REQUIREMENTS:
        Target Quality Level: {step["quality_requirement"]}
        Expected Output Format: {step["output_format"]}
        
        NEXT HANDOFF:
        Next Agent: {execution_plan["steps"][step["sequence_number"]]["agent"] if step["sequence_number"] < len(execution_plan["steps"]) else "Manager (Final Review)"}
        Expected Deliverable: {step["handoff_deliverable"]}
        """
        
        # 4. Esecuzione step con holistic pipeline
        step_result = await holistic_intelligent_pipeline(
            task_data=step,
            agent_id=selected_agent,
            workspace_id=workspace_id
        )
        
        # 5. Quality check + reprocessing se necessario
        quality_score = await evaluate_step_quality(step_result, step["quality_requirement"])
        
        if quality_score < 0.7:
            logger.info(f"üîÑ Quality below threshold ({quality_score:.2f}), reprocessing")
            step_result = await reprocess_with_enhanced_prompting(
                agent_id=selected_agent,
                original_result=step_result,
                quality_requirements=step["quality_requirement"],
                memory_patterns=step.get("quality_improvement_patterns", [])
            )
        
        # 6. Save high-quality results to memory
        if quality_score > 0.8:
            await save_high_quality_result_to_memory(step_result, workspace_id)
        
        results.append(step_result)
    
    return results
```

---

## ‚ö° **7. AUTONOMOUS GOAL RECOVERY FLOW**

### **Input**: Goals bloccati rilevati dal monitor
### **Output**: Autonomous task generation per sbloccare goal

```python
# FLUSSO CORE - NON MODIFICARE
async def autonomous_goal_recovery(workspace_id: str, stalled_goal_id: str):
    """‚ö° CORE FLOW: Recovery autonomo per goals bloccati"""
    
    # 1. Forza validazione goal al 0% (bypassa velocity optimizer)
    logger.info("üö® Goal at 0% progress - forcing validation regardless of workspace velocity")
    
    # 2. Analizza cause del blocco con AI + memoria
    blocking_analysis = await analyze_goal_blocking_factors(
        goal_id=stalled_goal_id,
        workspace_memory=await get_workspace_failure_patterns(workspace_id),
        recent_task_history=await get_recent_failed_tasks(stalled_goal_id)
    )
    
    # 3. Genera task di recovery con memoria-enhanced prompting
    recovery_tasks = await goal_driven_task_planner.generate_autonomous_tasks(
        goal_id=stalled_goal_id,
        workspace_id=workspace_id,
        recovery_context=blocking_analysis,
        memory_insights=await get_relevant_recovery_patterns(workspace_id)
    )
    
    # 4. Crea task con priority boost per recovery
    for task_data in recovery_tasks:
        task_data["priority"] += 1000  # FINALIZATION_TASK_PRIORITY_BOOST
        task_data["auto_generated"] = True
        task_data["recovery_attempt"] = True
        
        # Passa through holistic pipeline
        await holistic_intelligent_pipeline(task_data, task_data["agent_id"], workspace_id)
    
    # 5. Monitor recovery success
    await schedule_recovery_monitoring(stalled_goal_id, recovery_tasks)
    
    logger.info(f"üöÄ Autonomous recovery initiated for goal {stalled_goal_id}")
```

---

## üéº **SISTEMA INTEGRATION CHECKPOINTS**

### **Per ogni modifica al sistema, verificare:**

1. **‚úÖ Memory Integration**: Il flusso accede alla workspace memory?
2. **‚úÖ RAG Intelligence**: Considera documenti quando utile?  
3. **‚úÖ Quality Gates**: Valida prima dell'esecuzione?
4. **‚úÖ Learning Capture**: Salva insights per il futuro?
5. **‚úÖ Manager Coordination**: Coordina handoff multipli?
6. **‚úÖ Autonomous Recovery**: Gestisce goal bloccati automaticamente?

### **Anti-Patterns da EVITARE:**

- ‚ùå **Task generation senza memoria storica**
- ‚ùå **Execution senza quality gates**  
- ‚ùå **Results non salvati in memoria**
- ‚ùå **Handoff senza context precedente**
- ‚ùå **Goals al 0% ignorati dal sistema**
- ‚ùå **RAG hardcoded invece di intelligent triggering**

---

## üìä **HEALTH CHECK DELLO SISTEMA ORCHESTRATO**

```python
# Verifica periodica dell'integrit√† del sistema
async def system_orchestration_health_check():
    """Verifica che tutti i flussi core siano operativi"""
    
    checks = {
        "memory_integration": await test_workspace_memory_access(),
        "rag_intelligence": await test_intelligent_rag_trigger(),
        "quality_gates": await test_pre_execution_gates(),
        "learning_loops": await test_learning_capture(),
        "manager_coordination": await test_handoff_system(),
        "autonomous_recovery": await test_goal_recovery()
    }
    
    failed_components = [k for k, v in checks.items() if not v]
    
    if failed_components:
        logger.error(f"üö® ORCHESTRATION SYSTEM DEGRADED: {failed_components}")
        return False
    
    logger.info("‚úÖ All orchestration components operational")
    return True
```

---

## üèÜ **SUCCESS METRICS**

- **Score Review**: 92/100 (Production Ready)
- **Pillar Compliance**: 13/15 (93%)
- **Memory Integration**: ‚úÖ Operational 
- **RAG Intelligence**: ‚úÖ AI-driven triggering
- **Quality Gates**: ‚úÖ 6 gates system
- **Learning Loops**: ‚úÖ Continuous improvement
- **Manager Coordination**: ‚úÖ Multi-agent handoff
- **Autonomous Recovery**: ‚úÖ Self-healing goals

**Status**: **PRODUCTION READY** - Sistema orchestrato completo e operativo

---

> **üí° REMEMBER**: Questo sistema rappresenta un'evoluzione da task executor semplice a intelligenza artificiale collettiva. Ogni componente contribuisce all'intelligenza complessiva del sistema. **Preservare questi flussi √® critico per mantenere le capacit√† avanzate.**